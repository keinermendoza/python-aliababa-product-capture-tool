# Alibaba Scraper

Sistema que automatiza o processo de coleta de dados de produtos e fornecedores na plataforma Alibaba, com foco na busca e organizaÃ§Ã£o de cotaÃ§Ãµes de fornecedores internacionais.

A soluÃ§Ã£o combina uma **extensÃ£o personalizada do Google Chrome**, um **backend em Python com Flask**, um **banco de dados relacional** e uma **interface web** para visualizaÃ§Ã£o e exportaÃ§Ã£o dos dados coletados.

---

## InstalaÃ§Ã£o e Uso da ExtensÃ£o do Google Chrome

A extensÃ£o utilizada neste projeto Ã© uma **extensÃ£o personalizada do Google Chrome**, carregada em modo desenvolvedor.  
Ela Ã© responsÃ¡vel por coletar automaticamente os dados de produtos e fornecedores diretamente do site do Alibaba.

âš ï¸ **Importante:**  
Antes de utilizar a extensÃ£o, Ã© **obrigatÃ³rio** criar uma **Request for Quotation** na aplicaÃ§Ã£o web local desenvolvida com Flask.  
Todas as *quotations* coletadas pela extensÃ£o **devem estar associadas a uma request for quotation ativa**.

---

### InstalaÃ§Ã£o

#### Acesse a pasta do projeto
Entre no diretÃ³rio principal onde o cÃ³digo foi clonado.

```bash
cd python-aliababa-product-capture-tool
```

#### Crie o ambiente virtual 
Isso isola as dependÃªncias do projeto para nÃ£o interferir no seu sistema.

```bash
python -m venv venv
```

#### Ative o ambiente virtual:

- No Linux/Mac

```bash
source venv/bin/activate
```

- No Windows (PowerShell):

```powershell
.\venv\Scripts\Activate.ps1
```

#### Instale as dependÃªncias
Baixa e instala todos os pacotes necessÃ¡rios (como Flask e SQLAlchemy).

```bash
pip install -r requirements.txt
```

#### Inicialize o Banco de Dados

Dependendo do seu objetivo no projeto, escolha uma das opÃ§Ãµes abaixo para preparar o banco de dados:

##### Uso da App ou Desenvolvimento da ExtensÃ£o
Se vocÃª pretende capturar dados reais usando a extensÃ£o do Chrome ou quer testar a aplicaÃ§Ã£o do zero, crie um banco de dados vazio:

```bash
flask start_db
```
> Use esta opÃ§Ã£o se vocÃª for instalar a extensÃ£o para capturar produtos diretamente do Alibaba.

##### Desenvolvimento Backend (Sem ExtensÃ£o)
Se vocÃª quer contribuir para o cÃ³digo da aplicaÃ§Ã£o (Python/Flask) sem precisar instalar a extensÃ£o ou capturar dados manualmente, utilize o comando de seeding:

```bash
flask start_and_seed_db
```
> O banco de dados serÃ¡ criado e preenchido automaticamente com dados fictÃ­cios (sportive shoes, smartwatches, etc.), permitindo que vocÃª veja as funcionalidades da aplicaÃ§Ã£o imediatamente.
imento:


#### Execute a aplicaÃ§Ã£o
Inicia o servidor de desenvolvimento do Flask.

```bash
flask run
```

A aplicaÃ§Ã£o web ficarÃ¡ disponÃ­vel localmente (por padrÃ£o em `http://localhost:5000`).

---

### Criar uma Request for Quotation
> Caso tenha inicializado o banco de dados com o comando `start_and_seed_db` e pretenda contribuir apenas com o desenvolvimento do sistema, esta seÃ§Ã£o Ã© opcional. 

1. Acesse a aplicaÃ§Ã£o web local no navegador.
2. Na tela principal, crie uma nova **Request for Quotation**, informando:
   - Um tÃ­tulo
   - A quantidade desejada
3. ApÃ³s criada, a request serÃ¡ automaticamente marcada como **ativa**.

ğŸ“Œ Apenas **uma request for quotation ativa** pode receber novas quotations.  
A extensÃ£o sempre associarÃ¡ os dados coletados Ã  request ativa no momento do scraping.

---

### Instalar a extensÃ£o do Google Chrome
> Caso tenha inicializado o banco de dados com o comando `start_and_seed_db` e pretenda contribuir apenas com o desenvolvimento do sistema, esta seÃ§Ã£o Ã© opcional. 


1. Abra o Google Chrome.
2. Acesse:
   ```
   chrome://extensions
   ```
3. Ative o **Modo do desenvolvedor** no canto superior direito.
4. Clique em **â€œCarregar sem compactaÃ§Ã£oâ€** (*Load unpacked*).
5. Selecione a pasta **`product-scraper`** localizada na raiz do projeto.

ApÃ³s esses passos, a extensÃ£o estarÃ¡ instalada e pronta para uso.

---

### Utilizar a extensÃ£o para coletar dados
> Caso tenha inicializado o banco de dados com o comando `start_and_seed_db` e pretenda contribuir apenas com o desenvolvimento do sistema, esta seÃ§Ã£o Ã© opcional. 


1. Certifique-se de que:
   - O servidor Flask esteja em execuÃ§Ã£o.
   - Exista uma **request for quotation ativa** na aplicaÃ§Ã£o web local.

2. Acesse o site do **Alibaba** e navegue atÃ© a **pÃ¡gina de um produto especÃ­fico**  
   (nÃ£o utilize pÃ¡ginas de listagem ou resultados de busca).

3. Com a pÃ¡gina do produto aberta, utilize a **extensÃ£o do Google Chrome**, conforme demonstrado no vÃ­deo explicativo do projeto.

https://github.com/user-attachments/assets/ee6fb04f-e7f6-42ea-a42d-6c351ec54549


## VisÃ£o Geral da SoluÃ§Ã£o

O sistema Ã© composto por vÃ¡rias partes que trabalham de forma integrada:

- ExtensÃ£o do Google Chrome para coleta automÃ¡tica de dados diretamente das pÃ¡ginas de produtos do Alibaba.
- Servidor web local em Python (Flask) responsÃ¡vel por receber, processar e persistir os dados.
- Banco de dados relacional (SQLite) para armazenar requests for quotation e quotations.
- ComunicaÃ§Ã£o em tempo real com Socket.IO para sincronizaÃ§Ã£o automÃ¡tica da interface.
- ExportaÃ§Ã£o de dados para CSV para geraÃ§Ã£o de relatÃ³rios.

---

## Estrutura do Projeto

```
â”œâ”€â”€ app.py
â”œâ”€â”€ csv
â”œâ”€â”€ migrations
â”‚   â””â”€â”€ 0001_alter_table_names.sql
â”œâ”€â”€ product-scraper
â”‚   â”œâ”€â”€ content.js
â”‚   â”œâ”€â”€ manifest.json
â”‚   â”œâ”€â”€ popup.html
â”‚   â””â”€â”€ popup.js
â”œâ”€â”€ README.md
â”œâ”€â”€ repository.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ schema.py
â”œâ”€â”€ sheets.py
â”œâ”€â”€ templates
â”‚   â”œâ”€â”€ quotation_edit.html
â”‚   â”œâ”€â”€ quotation_list.html
â”‚   â””â”€â”€ request_for_quotation_list.html
â”œâ”€â”€ utils.py
â””â”€â”€ fake.py
```

---

## product-scraper

DiretÃ³rio que contÃ©m os arquivos da **extensÃ£o personalizada do Google Chrome** responsÃ¡vel pelo scraping.

O arquivo mais importante Ã© o **`content.js`**, onde:
- Os dados do produto e do fornecedor sÃ£o extraÃ­dos diretamente do DOM da pÃ¡gina do Alibaba.
- As informaÃ§Ãµes coletadas sÃ£o enviadas para o servidor Flask local atravÃ©s de uma requisiÃ§Ã£o HTTP (`/webhook`).

---

## app.py

Arquivo principal da aplicaÃ§Ã£o backend.

Responsabilidades principais:

- Inicializa o servidor Flask.
- Configura CORS para permitir requisiÃ§Ãµes apenas do domÃ­nio do Alibaba.
- Define o endpoint `/webhook`, responsÃ¡vel por:
  - Receber os dados enviados pela extensÃ£o.
  - Persistir as cotaÃ§Ãµes no banco de dados.
  - Emitir eventos via Socket.IO para atualizar a interface em tempo real.
- Define endpoints para:
  - Criar e listar **requests for quotation**.
  - Listar **quotations** associadas a uma request.
  - Gerar arquivos CSV com as cotaÃ§Ãµes.
- Define um comando customizado do Flask para inicializar o banco de dados.

---

## templates

ContÃ©m os templates HTML que compÃµem o frontend da aplicaÃ§Ã£o.

- **request_for_quotation_list.html**  
  Permite criar e ativar uma *request for quotation*.  
  Lista todas as requests cadastradas, exibindo a quantidade de quotations associadas a cada uma.

- **quotation_list.html**  
  Exibe todas as *quotations* relacionadas a uma *request for quotation* especÃ­fica.  
  Esses dados sÃ£o extraÃ­dos diretamente do site do Alibaba.

- **quotation_edit.html**  
  Exibe todas as propriedades de uma *quotation*, permitindo a ediÃ§Ã£o de algumas delas.

---

## schema.py

Define o esquema do banco de dados utilizando **SQLAlchemy Core**.

Este mÃ³dulo atua como a camada de definiÃ§Ã£o das tabelas e da estrutura do banco, fazendo a ponte entre o banco de dados relacional e a aplicaÃ§Ã£o Python.

---

## repository.py

ContÃ©m a classe **`SQLAlchemyRepository`**, responsÃ¡vel por **todas as interaÃ§Ãµes com o banco de dados**.

- Toda comunicaÃ§Ã£o com o banco deve ser feita exclusivamente atravÃ©s desta classe.
- Centraliza a lÃ³gica de persistÃªncia, consultas e atualizaÃ§Ãµes.

---

## sheets.py

ResponsÃ¡vel pela exportaÃ§Ã£o dos dados.

Atualmente:
- Exporta as cotaÃ§Ãµes para o formato **CSV**.
- Os arquivos gerados sÃ£o salvos no diretÃ³rio `csv/`.

---

## utils.py

MÃ³dulo de utilidades auxiliares.

- **slugify**  
  Gera strings seguras para nomes de arquivos e URLs.

- **copy_buyer_script_to_clipboard**  
  Copia automaticamente um script com informaÃ§Ãµes do comprador para a Ã¡rea de transferÃªncia.

---

## Requisitos

- Python 3.10+
- Google Chrome
- Git (opcional)

---

## VariÃ¡veis de Ambiente

```
BUYER_NAME
BUYER_ADDRESS
```

---

## ObservaÃ§Ãµes Finais

Projeto desenvolvido a partir da combinaÃ§Ã£o entre estudo acadÃªmico e aprendizado autodidata.
